\section{Evaluation}
We implement the tool PrefixMap with 2 Machine Translation engines.Since the idea of PrefixMap can also be applicable in different types of documents, we provide our experiment from all 3 types of documentations. They are Natural Language, Software Documentation and Programming Language. We also discuss on our results on comparing between Neural Machine Translation versus Statistical Machine Translation on this problem. We target to have the information about the prefix resolution based on different types of code tokens. In general, we want to answer the following research questions:

\begin{enumerate}
\item RQ1: Is prefix resolution important in programming language?
\item RQ2: Does NMT outperform SMT on PrefixMap by NLP translation evaluation metrics?
\item RQ3: Does NMT outperform SMT on PrefixMap by SE translation evaluation metrics?
\item RQ4: How SMT and NMT perform with different types of code prefixes?
\item RQ5: How SMT and NMT perform with ambiguous code prefixes?
\end{enumerate}

\subsection{Metrics for MT Evaluation}
We use 2 metrics reflect the view point of NLP and SE: the BLEU score and the exact matching accuracy. 
\\
\textbf{BLEU}. Bilingual Evaluation Understudy score, called the BLEU score, is the fundamental metric for comparing the actual output and expected output of the MT problem \cite{045}.  The BLEU score will take input as pair of expected and translated result, it will output as the score from 0 to 1 to reflect the similarity at n-gram level of word. The higher of BLEU, the better of translation engine performed. This score is calculated based on the co-occurrence at of n-gram between expected and translated sentence along with strategies for penalty and smoothing \cite{045}. We select the n-gram at 4-gram, and using the BLEU score implementation from Google NMT \cite{040}.

\textbf{Exact Match Accuracy}. In our MT problem, the requirement of good translation is not only restricted at the similar at n-gram. Similar to \cite{028}, another translation based approach in Software Engineering, we evaluate the Exact Match Accuracy at words level. Given the ith index of source sequence $prefix_{i}$ and of the expected sequence $expect_{i}$ and of the translated sequence $translate_{i}$, we compare the match between the $expect_{i}$ and $translate_{i}$. Since we have training data and testing data, we have Out of Vocabulary (OOV) cases. OOV has 2 types: Out of Source (OOS) means $prefix_{i}$ didn't appear in the training data and Out of Target (OOT) means $expect_{i}$ didn't exist in the training data. Since the prefix mapping process should suggest meaningful code token, we avoid evaluating the cases that the expected token was the same with prefix token. 

\subsection{Corpus Preparation}
We do the evaluation on 3 types of documentation:
\\
\textbf{Natural Language}. We collect all English sentences from the large scale corpus of English-German translation in NLP in \cite{040}. This corpus contains 1,15 millions sentences. 
\\
\textbf{Software Documentation}.We use the Conala corpus from \cite{046}. This corpus contains Python software documentation as 116000 English sentences.
\\
\textbf{Programming Language}.We collect 1000 Java projects from MSR 2013 corpus \cite{031}. We extract 560000 pairs of source and target tokens. The algorithm for extracting source and target language can be found in section 3.

For the variation of n-letter prefixes, we do the evaluation based on 3 levels: 1-letter prefix, 3-letters prefixes and 9-letters prefixes.




\subsection{MT Models Configurations}
Both SMT and NMT are run in a high end computer with Core i7 processor, 32 GB of RAM memory and using Nvidia RTX 2080 with 8GB of GPU.
\subsubsection{Statistical Machine Translation}
We use the default configuration suggested by Phrasal \cite{021}.The details of configuration is shown in \ref{tblConfigSMT}.
\begin{table}[]
\small
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Key }             & \textbf{Value} \\ \hline
MAX\_PHRASE\_LEN & 7     \\ \hline
Memory           & 26 GB \\ \hline
ttable-limit     & 250   \\ \hline
distortion-limit & 50    \\ \hline
stack            & 100   \\ \hline
\end{tabular}
\caption{Configuration of Statistical Machine Translation Model}
\label{tblConfigSMT}
\end{table}

\subsubsection{Neural Machine Translation}
Number of units in each hidden layer affects the accuracy \cite{047}. Increasing number of hidden unit can improve the accuracy but reduce the time performance since we need to change the batch size. So for NMT, we have 2 configurations as shown in Table \ref{tblConfigNMTs}.





\begin{table}[]
\small
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Key}                & \textbf{Config A (512 units)} & \textbf{Config B (1024 units)} \\ \hline
attention                   & normed\_bahdanau              & normed\_bahdanau               \\ \hline
attention\_architecture     & gnmt\_v2                      & gnmt\_v2                       \\ \hline
\textbf{batch\_size}        & \textbf{32}                   & \textbf{16}                    \\ \hline
beam\_width                 & 10                            & 10                             \\ \hline
decay\_scheme               & luong10                       & luong10                        \\ \hline
dropout                     & 0.2                           & 0.2                            \\ \hline
encoder\_type               & gnmt                          & gnmt                           \\ \hline
\textbf{infer\_batch\_size} & \textbf{32}                   & \textbf{16}                    \\ \hline
infer\_mode                 & greedy                        & greedy                         \\ \hline
init\_op                    & uniform                       & uniform                        \\ \hline
init\_weight                & 0.1                           & 0.1                            \\ \hline
learning\_rate              & 1                             & 1                              \\ \hline
length\_penalty\_weight     & 1                             & 1                              \\ \hline
num\_decoder\_layers        & 2                             & 2                              \\ \hline
num\_encoder\_layers        & 2                             & 2                              \\ \hline
\textbf{num\_train\_steps}         & \textbf{340000}                  & \textbf{680000} 
 \\ \hline
\textbf{num\_units}         & \textbf{512}                  & \textbf{1024} 
\\ \hline
optimizer                   & sgd                           & sgd                            \\ \hline
share\_vocab                & FALSE                         & FALSE                          \\ \hline
src\_max\_len               & 255                           & 255                            \\ \hline
steps\_per\_stats           & 100                           & 100                            \\ \hline
\end{tabular}
\caption{Configuration of Neural Machine Translation Models}
\label{tblConfigNMTs}
\end{table}



\subsection{Analysis on Length of Tokens in NL, SD and PL}
To answer RQ1, we analyze the average length of tokens in the target language of our NL, SD and PL corpus. The result is shown in Table \ref{tblAnalyzeOnPrefixLength}. By this table, we show that the average length of words in NL is over 6 letters in English. This is consistent with our hypothesis since we consider that NL usually intend to describe a single word in a token. Besides, the size of vocabulary in in NL corpus is around 20000, which is feasible for NMT to train and get the result without removing any unknown tokens.

For the SD and PL corpus, the result shows different characteristics of these data. For the average length, the PL corpus gains highest length of letter per separate words at over 16. THe PL also reveals a high average length of letters as over 11. This is the expected result, since in SD and PL, sentences are usually made by developers. Unlike NL, developers have to mention about AST elements such as method names and class names, which increases the number of letters per each tokens. This means the code completion tool that allows getting code from prefix is needed.

The other points from \ref{tblAnalyzeOnPrefixLength} also shows that the vocabulary size of each corpus are varied. In constrast to NL, the SD and PL corpus contains a remarkably bigger vocabulary. In our assumption, this fact is due to 2 reasons. First, the PL and SD contains tokens that mentioned several words. It means that they can be combination of tuple or triple of words instead of uni-word per token like NL. Secondly, the SD and PL can be developed by many developers with different code naming style, which cause many rare words appeared in the corpus.


\begin{table}[]
\small
\begin{tabular}{|l|l|l|}
\hline
\textbf{Target Languages}                                & \textbf{Vocab size}                                                    & \textbf{Average token length}                                                              \\ \hline
Natural Language                                & 19038                                                   & 6.08                                                              \\ \hline
Software Documentation                          & 134886                                                  & 11.77                                                             \\ \hline
Programming Language                            & 541275                                                  & 18.38                                                             \\ \hline
\end{tabular}
\caption{Analysis on Length of Tokens in NL, SD and PL}
\label{tblAnalyzeOnPrefixLength}
\end{table}

\subsection{BLEU Score Evaluation for Prefix Mapping NL, SD and PL}
In this experiment, we provide the translation for both NL, SD and PL corpus for SMT and configuration A of the SMT. The results are shown in Table \ref{tblBLEUScoreNLSDPL} and Table \ref{tblBLEUScoreConfigAAndB}. Along with these experiments, we have a verification experiment, which we run the configuration A on the English-German translation by \cite{040}. We got the accuracy of BLEU score at \textbf{29.74} compared to \textbf{29.9} of Google NMT, which shows the validity of our NMT configurations. For NL SD, we use 1-letter prefix as the source language.

From Table \ref{tblBLEUScoreNLSDPL}, we show that the increasing of BLEU score from NL, SD to PL. The NL has the lowest BLEU score. The reason is that we are doing the mapping from a context of 26 letters in NL to the target tokens which contains 19000 words, which caused challenges for the MT models. The PL corpus at 1-letter prefix returns surprisingly higher BLEU score. It shows the potential of capturing the code tokens based on code context can be better than in NL and SD. The BLEU score increases if we change the length of the prefixes.

We talk about the comparison between MT models. We got the accuracy of SMT outperforms the NMT with all of the corpus. This fact shows the strength of SMT to resolve the characteristic of consistent order between source and target language. We have a comparison of BLEU score between configuration A and B. It shows that the accuracy in configuration B increases, which shows the important of increasing number of hidden units.




\begin{table}[]
\small
\begin{tabular}{|l|l|l|}
\hline
\multicolumn{1}{|c|}{\textbf{Problems}}   & \multicolumn{1}{c|}{\textbf{SMT}} & \multicolumn{1}{c|}{\textbf{NMT (config A)}} \\ \hline
Natural Language                          & 13.36                             & 8.67                                         \\ \hline
Software Documentation                    & 53.11                             & 24.09                                        \\ \hline
Programming Language (1-letter prefixes)  & 63.4                              & 53.99                                        \\ \hline
Programming Language (5-letters prefixes) & 84.9                              & 64.33                                        \\ \hline
Programming Language (9-letters prefixes) & 92.61                             & 74.42                                        \\ \hline
\end{tabular}
\caption{BLEU Score Evaluation using SMT and NMT in NL, SD and PL}
\label{tblBLEUScoreNLSDPL}
\end{table}

\begin{table*}[]
\small
\begin{tabular}{|l|l|l|}
\hline
\multicolumn{1}{|c|}{\textbf{Problems}}   & \multicolumn{1}{c|}{\textbf{NMT (Config A)}} & \multicolumn{1}{c|}{\textbf{NMT (Config B)}} \\ \hline
Programming Language (1-letter prefixes)  & 53.99                                        & 52.78                                        \\ \hline
Programming Language (5-letters prefixes) & 64.33                                        & 73.39                                        \\ \hline
Programming Language (9-letters prefixes) & 74.42                                        & 79.12                                        \\ \hline
\end{tabular}
\caption{BLEU Score Comparison between Config A and B of NMT}
\label{tblBLEUScoreConfigAAndB}
\end{table*}


\subsection{Exact Match Accuracy Comparison of Prefix Mapping in NL, SD and PL}
The exact match accuracy are shown in Table \ref{tblExactMatchAccuracySMTAndNMT} and Table \ref{tblExactMatchAccuracyNMTConfigB}. From these tables, we show the accuracy of the prefix resolution varied depending on the types of n-letters prefixes. First, we see that we don't have the OOS case in the NL, SD and PL. This makes sense since the fact that we have a vocabulary of less than 100 prefixes in the source language of these configuration. However, with the SMT, we achieve over \textbf{65\%} of precision score, showing the strength of SMT in this type of problem. For 9-letter prefixes, the accuracy gained to \textbf{90\%}, means if developers wrote 9 letters of the code token, there are 9 per 10 cases the tool suggested correctly. We didn't include the non-useful suggestions counted to this accuracy. In the other words, the expected tokens need to be longer in letter than the prefixes.

For the NMT, the result is lower remarkably for Config A but improve in Config B. We got the accuracy ranged from 61\% from 1-letter prefix to 74\% for 9-letters prefixes for configuration A of NMT. For configuration B, the precision ranked from 58.62\% to 82.55\%. Though the gap between configuration B and SMT is only 8\%, the other problem of the NMT is the OOV tokens. For 9-prefixes letter, we got the OOV of NMT as high as third times the OOV of SMT. This is caused by the fact that there is a set of words required to change to Unknown words, which can badly impact the total accuracy of NMT.


\begin{table*}[]
\small
\begin{tabular}{|l|l|l|l|l|l|l|l|l|}
\hline
\textbf{Problems}                         & \multicolumn{8}{c|}{\textbf{SMT}}                                                                                                       \\ \hline
\textbf{}                                 & \textbf{Correct} & \textbf{Incorrect} & \textbf{OOS} & \textbf{OOT} & \textbf{OOV} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\ \hline
Natural Language                          & 12671            & 35890              & 0            & 196          & 196          & 26.09\%            & 98.48\%         & 41.25\%     \\ \hline
Software Documentation                    & 40656            & 20176              & 0            & 1855         & 1855         & 66.83\%            & 95.64\%         & 78.68\%     \\ \hline
PL (1-letter prefixes)  & 53868            & 28529              & 0            & 4090         & 4090         & 65.38\%            & 92.94\%         & 76.76\%     \\ \hline
PL (5-letters prefixes) & 40164            & 7897               & 540          & 3337         & 3877         & 83.57\%            & 91.20\%         & 87.22\%     \\ \hline
PL (9-letters prefixes) & 20554            & 2207               & 1374         & 1753         & 3127         & 90.30\%            & 86.80\%         & 88.51\%     \\ \hline
                                          & \multicolumn{8}{c|}{\textbf{NMT (Config A)}}                                                                                            \\ \hline
\textbf{}                                 & \textbf{Correct} & \textbf{Incorrect} & \textbf{OOS} & \textbf{OOT} & \textbf{OOV} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\ \hline
Natural Language                          & 10487            & 38074              & 0            & 196          & 196          & 21.60\%            & 98.17\%         & 35.40\%     \\ \hline
Software Documentation                    & 26237            & 31700              & 0            & 4750         & 4750         & 45.29\%            & 84.67\%         & 59.01\%     \\ \hline
PL (1-letter prefixes)  & 44510            & 28711              & 0            & 13266        & 13266        & 60.79\%            & 77.04\%         & 67.96\%     \\ \hline
PL (5-letters prefixes) & 25565            & 13895              & 3758         & 8720         & 12478        & 64.79\%            & 67.20\%         & 65.97\%     \\ \hline
PL (9-letters prefixes) & 11778            & 4217               & 7263         & 2630         & 9893         & 73.64\%            & 54.35\%         & 62.54\%     \\ \hline
\end{tabular}
\caption{Exact Match Accuracy Comparison between SMT and NMT Config A}
\label{tblExactMatchAccuracySMTAndNMT}
\end{table*}


\begin{table*}[]
\small
\begin{tabular}{|l|l|l|l|l|l|l|l|l|}
\hline
\multicolumn{1}{|c|}{\textbf{Problems}}             & \multicolumn{8}{c|}{\textbf{NMT (Config B)}}                               \\ \hline
                                                    & Correct & Incorrect & OOS  & OOT   & OOV   & Precision & Recall  & F1      \\ \hline
PL (1-letter prefixes)  & 42919   & 30302     & 0    & 13266 & 13266 & 58.62\%   & 76.39\% & 66.33\% \\ \hline
PL (5-letter prefixes) & 30853   & 8607      & 3758 & 8720  & 12478 & 78.19\%   & 71.20\% & 74.53\% \\ \hline
PL (9-letter prefixes) & 13204   & 2791      & 7263 & 2630  & 9893  & 82.55\%   & 57.17\% & 67.55\% \\ \hline
\end{tabular}
\caption{Exact Match Accuracy Comparison of NMT model Config B}
\label{tblExactMatchAccuracyNMTConfigB}
\end{table*}

\subsection{Analysis on Types of Tokens in Naming Conventions for Prefixes}
To setup this experiment, we provide a module that check the regular expression of each tokens in the testing data set. There are regular expressions on checking if a numeric, a class name, a variable, a method name or a string literal. We found and add the regular expressions for checking at well-known online resource as \cite{048,049}. Considering the Configuration B as a higher accuracy NMT model compared to configuration A. The results are shown in Table \ref{tblAnaTypeTokensSMT} and Table \ref{tblAnaTypeTokensNeuralMT}.

The result shows the consistent between NMT and SMT configuration. The two types of token received lowest accuracy is Numeric and String literal. The numeric tokens got precision as 34\% in 1-letter prefix of SMT and got 24.71\% in 1-letter prefix of NMT configuration B. The String literal got 28\% in each configuration. This fact reveals the challenge of code suggestion for numeric and string literal, since the they are not only depend on the tokens but also depend on the control flow or data flow graph of the program. For main types of tokens, we got the highest accuracy for class name while the variable name and constanct tokens achieved the equal results in both SMT and NMT. It is explainable since the good class names can be reused popular by developers which helps the SMT model to learn the prediction. Method name, in the other hands, varied based on the purpose of each developers.

\begin{table}[]
\tiny
\begin{tabular}{|l|l|l|l|l|l|l|l|l|}
\hline
\multicolumn{9}{|c|}{\textbf{SMT (1-letter prefixes)}}                                        \\ \hline
Type of Tokens     & Correct & Incorrect & OOS  & OOT  & OOV  & Precision & Recall  & F1      \\ \hline
Total:             & 53868   & 28529     & 0    & 4090 & 4090 & 65.38\%   & 92.94\% & 76.76\% \\ \hline
NumericType:       & 163     & 304       & 0    & 28   & 28   & 34.90\%   & 85.34\% & 49.54\% \\ \hline
ClassNameType:     & 6154    & 2793      & 0    & 317  & 317  & 68.78\%   & 95.10\% & 79.83\% \\ \hline
VariableType:      & 26937   & 14888     & 0    & 1503 & 1503 & 64.40\%   & 94.72\% & 76.67\% \\ \hline
MethodNameType:    & 12908   & 6695      & 0    & 501  & 501  & 65.85\%   & 96.26\% & 78.20\% \\ \hline
StringLiteralType: & 628     & 1585      & 0    & 841  & 841  & 28.38\%   & 42.75\% & 34.11\% \\ \hline
ConstanctType:     & 1321    & 821       & 0    & 281  & 281  & 61.67\%   & 82.46\% & 70.57\% \\ \hline
OtherType:         & 5757    & 1443      & 0    & 619  & 619  & 79.96\%   & 90.29\% & 84.81\% \\ \hline
\multicolumn{9}{|c|}{\textbf{SMT (5-letter prefixes)}}                                        \\ \hline
Total:             & 40164   & 7897      & 540  & 3337 & 3877 & 83.57\%   & 91.20\% & 87.22\% \\ \hline
NumericType:       & 81      & 65        & 7    & 12   & 19   & 55.48\%   & 81.00\% & 65.85\% \\ \hline
ClassNameType:     & 6986    & 755       & 40   & 270  & 310  & 90.25\%   & 95.75\% & 92.92\% \\ \hline
VariableType:      & 17271   & 3861      & 258  & 1096 & 1354 & 81.73\%   & 92.73\% & 86.88\% \\ \hline
MethodNameType:    & 10924   & 2057      & 23   & 474  & 497  & 84.15\%   & 95.65\% & 89.53\% \\ \hline
StringLiteralType: & 1219    & 389       & 100  & 730  & 830  & 75.81\%   & 59.49\% & 66.67\% \\ \hline
ConstanctType:     & 1182    & 404       & 29   & 243  & 272  & 74.53\%   & 81.29\% & 77.76\% \\ \hline
OtherType:         & 2501    & 366       & 83   & 512  & 595  & 87.23\%   & 80.78\% & 83.88\% \\ \hline
\multicolumn{9}{|c|}{\textbf{SMT (9-letter prefixes)}}                                        \\ \hline
Total:             & 20554   & 2207      & 1374 & 1753 & 3127 & 90.30\%   & 86.80\% & 88.51\% \\ \hline
NumericType:       & 11      & 3         & 2    & 0    & 2    & 78.57\%   & 84.62\% & 81.48\% \\ \hline
ClassNameType:     & 4279    & 233       & 116  & 160  & 276  & 94.84\%   & 93.94\% & 94.39\% \\ \hline
VariableType:      & 6436    & 950       & 511  & 431  & 942  & 87.14\%   & 87.23\% & 87.19\% \\ \hline
MethodNameType:    & 6963    & 557       & 185  & 279  & 464  & 92.59\%   & 93.75\% & 93.17\% \\ \hline
StringLiteralType: & 868     & 179       & 288  & 456  & 744  & 82.90\%   & 53.85\% & 65.29\% \\ \hline
ConstanctType:     & 923     & 155       & 104  & 114  & 218  & 85.62\%   & 80.89\% & 83.19\% \\ \hline
OtherType:         & 1074    & 130       & 168  & 313  & 481  & 89.20\%   & 69.07\% & 77.85\% \\ \hline
\end{tabular}
\caption{Analysis Result on Types of Tokens for Prefix Mapping by SMT}
\label{tblAnaTypeTokensSMT}
\end{table}

\begin{table*}[]
\small
\begin{tabular}{|l|l|l|l|l|l|l|l|l|}
\hline
\multicolumn{9}{|c|}{\textbf{NMT in Config B (1-letter prefixes)}}                                                                                                \\ \hline
\textbf{Type of Tokens} & \textbf{Correct} & \textbf{Incorrect} & \textbf{OOS} & \textbf{OOT} & \textbf{OOV} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\ \hline
Total:                  & 42919            & 30302              & 0            & 13266        & 13266        & 58.62\%            & 76.39\%         & 66.33\%     \\ \hline
NumericType:            & 86               & 262                & 0            & 147          & 147          & 24.71\%            & 36.91\%         & 29.60\%     \\ \hline
ClassNameType:          & 4554             & 3343               & 0            & 1367         & 1367         & 57.67\%            & 76.91\%         & 65.91\%     \\ \hline
VariableType:           & 21774            & 16366              & 0            & 5188         & 5188         & 57.09\%            & 80.76\%         & 66.89\%     \\ \hline
MethodNameType:         & 10742            & 7065               & 0            & 2297         & 2297         & 60.32\%            & 82.38\%         & 69.65\%     \\ \hline
StringLiteralType:      & 354              & 902                & 0            & 1798         & 1798         & 28.18\%            & 16.45\%         & 20.77\%     \\ \hline
ConstanctType:          & 875              & 586                & 0            & 962          & 962          & 59.89\%            & 47.63\%         & 53.06\%     \\ \hline
OtherType:              & 4534             & 1778               & 0            & 1507         & 1507         & 71.83\%            & 75.05\%         & 73.41\%     \\ \hline
\multicolumn{9}{|c|}{\textbf{NMT in Config B (5-letters prefixes)}}                                                                                               \\ \hline
Total:                  & 30853            & 8607               & 3758         & 8720         & 12478        & 78.19\%            & 71.20\%         & 74.53\%     \\ \hline
NumericType:            & 40               & 18                 & 84           & 23           & 107          & 68.97\%            & 27.21\%         & 39.02\%     \\ \hline
ClassNameType:          & 5473             & 1245               & 444          & 889          & 1333         & 81.47\%            & 80.41\%         & 80.94\%     \\ \hline
VariableType:           & 13575            & 4153               & 1402         & 3356         & 4758         & 76.57\%            & 74.05\%         & 75.29\%     \\ \hline
MethodNameType:         & 8843             & 2366               & 227          & 2042         & 2269         & 78.89\%            & 79.58\%         & 79.23\%     \\ \hline
StringLiteralType:      & 512              & 202                & 862          & 862          & 1724         & 71.71\%            & 22.90\%         & 34.71\%     \\ \hline
ConstanctType:          & 727              & 223                & 305          & 603          & 908          & 76.53\%            & 44.46\%         & 56.25\%     \\ \hline
OtherType:              & 1683             & 400                & 434          & 945          & 1379         & 80.80\%            & 54.96\%         & 65.42\%     \\ \hline
\multicolumn{9}{|c|}{\textbf{NMT in Config B (9-letters prefixes)}}                                                                                               \\ \hline
Total:                  & 13204            & 2791               & 7263         & 2630         & 9893         & 82.55\%            & 57.17\%         & 67.55\%     \\ \hline
NumericType:            & 6                & 3                  & 6            & 1            & 7            & 66.67\%            & 46.15\%         & 54.55\%     \\ \hline
ClassNameType:          & 3082             & 580                & 827          & 299          & 1126         & 84.16\%            & 73.24\%         & 78.32\%     \\ \hline
VariableType:           & 3632             & 1244               & 2645         & 807          & 3452         & 74.49\%            & 51.27\%         & 60.74\%     \\ \hline
MethodNameType:         & 5254             & 673                & 1335         & 722          & 2057         & 88.65\%            & 71.86\%         & 79.38\%     \\ \hline
StringLiteralType:      & 251              & 75                 & 1168         & 297          & 1465         & 76.99\%            & 14.63\%         & 24.58\%     \\ \hline
ConstanctType:          & 456              & 91                 & 632          & 117          & 749          & 83.36\%            & 37.84\%         & 52.05\%     \\ \hline
OtherType:              & 523              & 125                & 650          & 387          & 1037         & 80.71\%            & 33.53\%         & 47.37\%     \\ \hline
\end{tabular}
\caption{Analysis Result on Types of Tokens for Prefix Mapping by NMT}
\label{tblAnaTypeTokensNeuralMT}
\end{table*}

\subsection{Analysis on the Accuracy of PrefixMap on Ambiguous Tokens}
In the last experiment, we analyze the affect of the number of mapping prefixes to code tokens can affect the accuracy. For each prefix in the training set, we run a program to check how many distinct code tokens are mapped to that prefix in the target language. The prefix that has more mapped tokens can be considered as more ambiguous. The result can be shown in Table \ref{tblAnaPercentageMappingSMT} for SMT and Table \ref{tblAnaPercentageMappingNeuralMT} for NMT configuration B.

The first observation we got is that in 1-letter prefix, there is no case of mapping 1-1 to tokens in both SMT and NMT. This fact is explainable since the vocabulary of the source language contains only letters in alphabet and number digits, which are less than 100 prefixes. Besides, there are a large percentage of the prefixes has more than 100 mappings with 1-letter prefix corpus. For the 1-letter prefix, the SMT got accuracy about 70\% while the NMT got 59\% for very ambiguous tokens. For 5-letters and 9-letter prefixes, the accuracy of SMT decreases from unambiguous tokens to very ambiguous tokens. In the NMT with 9-letters prefix and for very ambiguous tokens, these tokens are considered as Unknown due to their rarely appeared in the data set, cause the NMT to decrease. In general, the SMT outperforms the NMT for almost all of accuracy experiments.


\begin{table}[]
\tiny
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
\multicolumn{7}{|c|}{\textbf{SMT (1-letter prefixes)}}                                                           \\ \hline
TokenType\textbackslash{}NumofMap & 1         & 2-10      & 11-20     & 21-50     & 51-100    & Greater than 100 \\ \hline
                                  & Precision & Precision & Precision & Precision & Precision & Precision        \\ \hline
NumericType:                      & 0.00\%    & 0.00\%    & 0.00\%    & 0.00\%    & 0.00\%    & 34.90\%          \\ \hline
ClassNameType:                    & 0.00\%    & 0.00\%    & 0.00\%    & 0.00\%    & 0.00\%    & 68.78\%          \\ \hline
VariableType:                     & 0.00\%    & 0.00\%    & 0.00\%    & 100.00\%  & 0.00\%    & 64.40\%          \\ \hline
MethodNameType:                   & 0.00\%    & 0.00\%    & 0.00\%    & 0.00\%    & 0.00\%    & 65.85\%          \\ \hline
StringLiteralType:                & 0.00\%    & 0.00\%    & 0.00\%    & 0.00\%    & 0.00\%    & 28.38\%          \\ \hline
ConstanctType:                    & 0.00\%    & 0.00\%    & 0.00\%    & 0.00\%    & 0.00\%    & 61.67\%          \\ \hline
OtherType:                        & 0.00\%    & 40.00\%   & 97.35\%   & 83.18\%   & 0.00\%    & 70.68\%          \\ \hline
Total of tokens:                  & 0         & 10        & 2416      & 221       & 1         & 79749            \\ \hline
Percentage:                       & 0.00\%    & 0.01\%    & 2.93\%    & 0.27\%    & 0.00\%    & 96.79\%          \\ \hline
\multicolumn{7}{|c|}{\textbf{SMT (5-letter prefixes)}}                                                           \\ \hline
NumericType:                      & 100.00\%  & 57.78\%   & 71.43\%   & 36.84\%   & 60.00\%   & 0.00\%           \\ \hline
ClassNameType:                    & 100.00\%  & 91.83\%   & 88.90\%   & 87.06\%   & 90.34\%   & 89.09\%          \\ \hline
VariableType:                     & 100.00\%  & 80.09\%   & 78.40\%   & 77.36\%   & 82.91\%   & 81.70\%          \\ \hline
MethodNameType:                   & 100.00\%  & 94.60\%   & 89.77\%   & 90.62\%   & 89.03\%   & 80.35\%          \\ \hline
StringLiteralType:                & 100.00\%  & 85.04\%   & 75.63\%   & 74.70\%   & 68.45\%   & 65.50\%          \\ \hline
ConstanctType:                    & 100.00\%  & 83.66\%   & 79.35\%   & 75.09\%   & 66.67\%   & 58.60\%          \\ \hline
OtherType:                        & 100.00\%  & 87.09\%   & 84.58\%   & 90.91\%   & 91.85\%   & 82.38\%          \\ \hline
Total of tokens:                  & 1980      & 6425      & 3375      & 6411      & 7017      & 22853            \\ \hline
Percentage:                       & 4.12\%    & 13.37\%   & 7.02\%    & 13.34\%   & 14.60\%   & 47.55\%          \\ \hline
\multicolumn{7}{|c|}{\textbf{SMT (9-letter prefixes)}}                                                           \\ \hline
NumericType:                      & 100.00\%  & 100.00\%  & 50.00\%   & 75.00\%   & 0.00\%    & 0.00\%           \\ \hline
ClassNameType:                    & 100.00\%  & 94.22\%   & 90.73\%   & 89.12\%   & 89.56\%   & 83.10\%          \\ \hline
VariableType:                     & 100.00\%  & 84.45\%   & 77.86\%   & 72.23\%   & 74.80\%   & 57.25\%          \\ \hline
MethodNameType:                   & 100.00\%  & 92.64\%   & 87.54\%   & 91.82\%   & 85.10\%   & 80.07\%          \\ \hline
StringLiteralType:                & 100.00\%  & 84.38\%   & 69.66\%   & 68.29\%   & 71.74\%   & 59.85\%          \\ \hline
ConstanctType:                    & 100.00\%  & 80.74\%   & 66.27\%   & 72.46\%   & 64.71\%   & 66.67\%          \\ \hline
OtherType:                        & 100.00\%  & 88.58\%   & 81.52\%   & 90.79\%   & 88.46\%   & 53.33\%          \\ \hline
Total of tokens:                  & 6360      & 9952      & 1808      & 2550      & 1302      & 789              \\ \hline
Percentage:                       & 27.94\%   & 43.72\%   & 7.94\%    & 11.20\%   & 5.72\%    & 3.47\%           \\ \hline
\end{tabular}
\caption{Analysis Result on How PrefixMapping can handle Ambiguous Tokens by SMT}
\label{tblAnaPercentageMappingSMT}
\end{table}

\begin{table*}[]
\small
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
\multicolumn{7}{|c|}{\textbf{NMT in Config B (1-letter prefixes)}}                                                                                                              \\ \hline
\textbf{TokenType\textbackslash{}NumofMap} & \textbf{1}         & \textbf{2-10}      & \textbf{11-20}     & \textbf{21-50}     & \textbf{51-100}    & \textbf{\textgreater 100} \\ \hline
                                           & \textbf{Precision} & \textbf{Precision} & \textbf{Precision} & \textbf{Precision} & \textbf{Precision} & \textbf{Precision}        \\ \hline
NumericType:                               & 0.00\%             & 0.00\%             & 66.67\%            & 29.79\%            & 30.77\%            & 23.16\%                   \\ \hline
ClassNameType:                             & 0.00\%             & 0.00\%             & 25.00\%            & 62.50\%            & 0.00\%             & 57.68\%                   \\ \hline
VariableType:                              & 0.00\%             & 0.00\%             & 0.00\%             & 0.00\%             & 19.64\%            & 57.15\%                   \\ \hline
MethodNameType:                            & 0.00\%             & 0.00\%             & 0.00\%             & 0.00\%             & 50.00\%            & 60.33\%                   \\ \hline
StringLiteralType:                         & 0.00\%             & 0.00\%             & 0.00\%             & 0.00\%             & 0.00\%             & 28.18\%                   \\ \hline
ConstanctType:                             & 0.00\%             & 0.00\%             & 66.67\%            & 0.00\%             & 0.00\%             & 59.96\%                   \\ \hline
OtherType:                                 & 0.00\%             & 89.25\%            & 50.00\%            & 66.29\%            & 35.29\%            & 58.76\%                   \\ \hline
Total:                                     & 0                  & 2661               & 32                 & 324                & 90                 & 70114                     \\ \hline
Percentage:                                & 0.00\%             & 3.63\%             & 0.04\%             & 0.44\%             & 0.12\%             & 95.76\%                   \\ \hline
\multicolumn{7}{|c|}{\textbf{NMT in Config B (5-letters prefixes)}}                                                                                                             \\ \hline
NumericType:                               & 76.47\%            & 66.67\%            & 64.29\%            & 0.00\%             & 0.00\%             & 0.00\%                    \\ \hline
ClassNameType:                             & 79.67\%            & 84.24\%            & 79.10\%            & 76.19\%            & 84.81\%            & 0.00\%                    \\ \hline
VariableType:                              & 70.64\%            & 74.03\%            & 78.03\%            & 85.35\%            & 64.47\%            & 57.97\%                   \\ \hline
MethodNameType:                            & 91.36\%            & 88.80\%            & 82.14\%            & 81.87\%            & 74.68\%            & 63.74\%                   \\ \hline
StringLiteralType:                         & 75.74\%            & 67.24\%            & 77.88\%            & 70.83\%            & 0.00\%             & 0.00\%                    \\ \hline
ConstanctType:                             & 87.64\%            & 76.84\%            & 75.58\%            & 47.73\%            & 53.42\%            & 0.00\%                    \\ \hline
OtherType:                                 & 92.73\%            & 75.98\%            & 73.26\%            & 88.68\%            & 77.80\%            & 83.33\%                   \\ \hline
Total:                                     & 3324               & 10580              & 6002               & 10938              & 5283               & 3333                      \\ \hline
Percentage:                                & 8.42\%             & 26.81\%            & 15.21\%            & 27.72\%            & 13.39\%            & 8.45\%                    \\ \hline
\multicolumn{7}{|c|}{\textbf{NMT in Config B (9-letters prefixes)}}                                                                                                             \\ \hline
NumericType:                               & 0.00\%             & 66.67\%            & 0.00\%             & 0.00\%             & 0.00\%             & 0.00\%                    \\ \hline
ClassNameType:                             & 83.72\%            & 86.38\%            & 76.40\%            & 68.18\%            & 0.00\%             & 0.00\%                    \\ \hline
VariableType:                              & 77.08\%            & 72.33\%            & 70.32\%            & 68.24\%            & 0.00\%             & 0.00\%                    \\ \hline
MethodNameType:                            & 92.88\%            & 88.57\%            & 80.41\%            & 67.58\%            & 77.50\%            & 0.00\%                    \\ \hline
StringLiteralType:                         & 78.17\%            & 71.43\%            & 87.10\%            & 0.00\%             & 0.00\%             & 0.00\%                    \\ \hline
ConstanctType:                             & 88.08\%            & 73.86\%            & 50.00\%            & 0.00\%             & 0.00\%             & 0.00\%                    \\ \hline
OtherType:                                 & 73.49\%            & 78.28\%            & 91.72\%            & 66.67\%            & 0.00\%             & 0.00\%                    \\ \hline
Total:                                     & 7403               & 6748               & 1300               & 504                & 40                 & 0                         \\ \hline
Percentage:                                & 46.28\%            & 42.19\%            & 8.13\%             & 3.15\%             & 0.25\%             & 0.00\%                    \\ \hline
\end{tabular}
\caption{Analysis Result on How PrefixMapping can handle Ambiguous Tokens by NMT}
\label{tblAnaPercentageMappingNeuralMT}
\end{table*}
